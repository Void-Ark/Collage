{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./hsb2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- how to do scipy.stats.mannwhitneyu in python \n",
    "- to use the mannwhitneyu we need the function in py. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perform the Mann-Whitney U rank test on two independent samples.\n",
    "\n",
    "The Mann-Whitney U test is a nonparametric test of the null hypothesis that the distribution underlying sample x is the same as the distribution underlying sample y. It is often used as a test of difference in location between distributions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find the value of p from the above equation\n",
    "    - p < .05 (5% segnificance level) : Null hypo. is rejected : which means there is a significance diff. b/w read and write \n",
    "    - p >= .05 : NULL hypo. is accepted : nosignificance diff. b/w read and write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL HYPOTHESIS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.423843181555109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statts, p = stats.mannwhitneyu(df['read'], df['write'])\n",
    "\n",
    "if p < .05 : \n",
    "    print('ALTERNATE HYPOTHESIS') \n",
    "else : \n",
    "    print(\"NULL HYPOTHESIS\")\n",
    "p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Wilcoxon signed-rank test.\n",
    "\n",
    "- The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences x - y is symmetric about zero. It is a non-parametric version of the paired T-test.\n",
    "- if the diff b/w the 2 var.s doesn't have a normal distribution then use stats.wilcoxon test.  \n",
    "- code : 'scipy.stats.wilcoxon(df['read'], df['write'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ttest_1samp: T-test for the mean of ONE group of scores \n",
    "\n",
    "- objective : is to see whether the performance of the student has meet the benchmark value \n",
    "    - null hypo (ho) : there is no significance diff. in the mean of read marks aginst the benchmark value of 60 \n",
    "        - if ho is accepted that the perforfmance of the student has meet my expection \n",
    "    - alternate hypo. (ha) : there is signoficance diff. in the mean of read marks against the benchmark of 60 \n",
    "- code : **t_stats, p_value = scipy.stats.ttest_1samp(df['read'], benchmark_value)** \n",
    "- make the interpretation of the p_value from the 1_sample_ttest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- objective\n",
    "- null hypo.\n",
    "- alternate hypo. \n",
    "- code : which test \n",
    "- code : statical parameter obtain \n",
    "- code : interpretation of the test "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to see whether the performance in the science sub. has met the benchmark value of 60 \n",
    "2. to see is there a significance diff. in the math subject b/w 0, 1 (Gender) \n",
    "3. is there significance diff. b/w science and social science\n",
    "4. to see is there a significance diff. in science subject b/w stu. of school types (1, 2)\n",
    "5. to see is there significance diff. b/w science and social science and data is coming from diff. student "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. to see whether the performance in the science sub. has met the benchmark value of 60\n",
    "\n",
    "- we use 1_sample_ttest \n",
    "- **null hypo (ho)** : there is no significance diff. in the mean of science marks aginst the benchmark value of 60 \n",
    "- **alternate hypo. (ha)** : there is signoficance diff. in the mean of science marks against the benchmark of 60 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.6412157170331 3.1711440800351243e-24\n",
      "NULL HYPOTHESIS\n"
     ]
    }
   ],
   "source": [
    "t_stats, p_value = stats.ttest_1samp(df['science'], 60)\n",
    "print(t_stats, p_value)\n",
    "hypo(p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT is **NULL HYPOTHESIS** means no significant difference "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. to see is there a significance diff. in the math subject b/w 0, 1 (Gender)\n",
    "\n",
    "- we use ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.41299864929688507 1.976\n"
     ]
    }
   ],
   "source": [
    "#boys = df[df['Gender']== 1]['math']\n",
    "#boys = boys.reset_index()\n",
    "#\n",
    "#girls = df[df['Gender']== 0]['math']\n",
    "#girls = girls.reset_index()\n",
    "#\n",
    "#diff = boys['math'] - girls['math'] \n",
    "#\n",
    "## for normality \n",
    "#diff_mean = diff.mean() \n",
    "#diff_std = diff.std() \n",
    "#    # for criteria 1\n",
    "#diff_x1 = diff_mean + diff_std \n",
    "#diff_x2 = diff_mean - diff_std \n",
    "#print(diff[(diff < diff_x1) & (diff > diff_x2)].size)\n",
    "#print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "#    # for criteria 2\n",
    "#diff_x1 = diff_mean + diff_std*2 \n",
    "#diff_x2 = diff_mean - diff_std*2 \n",
    "#print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "#    # for criteria 3\n",
    "#diff_x1 = diff_mean + diff_std*3 \n",
    "#diff_x2 = diff_mean - diff_std*3 \n",
    "#print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "\n",
    "t_stats, p_value = stats.ttest_ind(df[df['Gender'] == 1]['math'], df[df['Gender']==0]['math'])\n",
    "print(t_stats, 1.976)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. is there significance diff. b/w science and social science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "141\n",
      "0.705\n",
      "0.935\n",
      "0.99\n",
      "-0.7338002375049547 0.4639341426202652\n"
     ]
    }
   ],
   "source": [
    "diff = df['science'] - df['socst']\n",
    "print(diff.size)\n",
    "\n",
    "# for normality \n",
    "diff_mean = diff.mean() \n",
    "diff_std = diff.std() \n",
    "    # for criteria 1\n",
    "diff_x1 = diff_mean + diff_std \n",
    "diff_x2 = diff_mean - diff_std \n",
    "print(diff[(diff < diff_x1) & (diff > diff_x2)].size)\n",
    "print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "    # for criteria 2\n",
    "diff_x1 = diff_mean + diff_std*2 \n",
    "diff_x2 = diff_mean - diff_std*2 \n",
    "print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "    # for criteria 3\n",
    "diff_x1 = diff_mean + diff_std*3 \n",
    "diff_x2 = diff_mean - diff_std*3 \n",
    "print(diff[(diff < diff_x1) & (diff > diff_x2)].size/diff.size)\n",
    "\n",
    "t_stats, p_value = stats.ttest_rel(df['science'], df['socst'])\n",
    "print(t_stats, p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. to see is there a significance diff. in science subject b/w stu. of school types (1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9113221460646189 0.36323382141887817\n"
     ]
    }
   ],
   "source": [
    "t_stats, p_value = stats.ttest_ind(df[df['schtyp']==1]['science'], df[df['schtyp']==2]['science'])\n",
    "print(t_stats, p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
